{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 確率モデル\n",
    "\n",
    "- パラメトリックモデル 学習データから推定した統計量を用いて構成した確率モデルで分布を表現する。\n",
    "- ノンパラメトリックモデル 特定の確率モデルを仮定しない\n",
    "\n",
    "ノンパラメトリックモデルには、ヒストグラム法、k最近傍法(kNN)、パルツェン密度推定法などがある。\n",
    "\n",
    "パラメトリックモデルには、確率変数が離散的な物と、連続的な物がある。、\n",
    "\n",
    "## 4.2.1 正規分布\n",
    "正規分布に限り、無相関であることと統計的に独立であることが等価である。従って、共分散行列を対角化でき、統計的に独立な要素に分解できる。一次元正規分関数は\n",
    "$$\n",
    "N(x|\\mu, \\sigma^2) = \\frac{ 1}{ \\sqrt {2\\pi} \\sigma } exp(-\\frac{(x-\\mu)^2}{ 2\\sigma^2})\n",
    "$$\n",
    "で定義でき、正規分布の形を決めるパラメータは平均値$\\mu$と分散$\\sigma^2$である。\n",
    "\n",
    "確率変数がd個の要素を持つベクトルで与えられる場合、d次元の多次元正規分布問題となり、\n",
    "$$\n",
    "N(x|\\mu, \\Sigma) = \\frac {1} {(2\\pi)^{\\frac d 2} |\\Sigma |^{\\frac 1 2}} exp(- \\frac 2 1 (x - \\mu)^T \\Sigma^{-1}(x-\\mu))\n",
    "$$\n",
    "ここで、$\\mu$は平均ベクトル、$\\Sigma$は共分散行列をあらわす。\n",
    "\n",
    "任意の点xと平均ベクトル$\\mu$との距離\n",
    "$$\n",
    "d(x,\\mu) = \\sqrt {(x-\\mu)^T \\Sigma^{-1}(x-\\mu)}\n",
    "$$\n",
    "をマハラノビス距離という。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.2.2 正規分布から導かれる識別関数\n",
    "i番目のクラスのクラス条件付き確立が次の正規分布をしていると仮定する。\n",
    "$$\n",
    "p(x|C_i)=\\frac 1 {(2 \\pi ) ^ { \\frac d 2} | \\Sigma_i | ^ \\frac 1 2 } exp( - \\frac 1 2 (x-\\mu_i)^T \\Sigma_i^{-1} (x - \\mu_i))\n",
    "$$\n",
    "ベイズの誤り率最小識別規則を満たす識別関数を求める。クラスの事後確率を $P(C_i)$ とすると、事後確率は、\n",
    "$$\n",
    "P(C_i|x) = \\frac {p(x|C_i)P(C_i) } {p(x)} \t\\propto \\frac { p(C_i) } {(2 \\pi ) ^ { \\frac d 2} | \\Sigma_i | ^ \\frac 1 2 } exp( - \\frac 1 2 (x-\\mu_i)^T \\Sigma_i^{-1} (x - \\mu_i))\n",
    "$$\n",
    "最後の式の対数を取ると\n",
    "$$\n",
    "ln P(C_i) - \\frac d 2 ln(2 \\pi) - \\frac 1 2 ln | \\Sigma_i | - \\frac 1 2 (x - \\mu_i)^T \\Sigma_i^{-1}(x-\\mu_i) \n",
    "$$\n",
    "各クラスに共通に現れる講を省略し、符号を反転する。i番目のクラスの事後確率から導かれる評価値は\n",
    "$$\n",
    "g_i(x) = (x-\\mu_i)^T\\Sigma_i^{-1} + ln|\\Sigma_i| - 2 lnP(C_i)\n",
    "$$\n",
    "$$\n",
    "arg min_i[g_i(x)]\n",
    "$$\n",
    "クラス間の境界は2クラスの事後確率が等しくなるところの軌跡になる。\n",
    "\n",
    "$ f_{ij}(x) = g_i(x) - g_j(x) = x^TSx + 2c^Tx + F = 0 $となり２次曲面となる、\n",
    "\n",
    "２クラスの共分散行列が等しい場合、S=0となり、線形識別問題となる。\n",
    "$$ \n",
    "f_{ij}(x) = g_i(x) - g_j(x) = 2c^Tx + F = 0 \n",
    "$$\n",
    "\n",
    "2つのクラスの共分散行列が同じ等方向分散を持ち、クラスの事前確率が等しい場合。\n",
    "$$ \n",
    "f_{ij}(x) = g_i(x) - g_j(x) = 2 \\sigma^{-1} (\\mu_j^T - \\mu_i^T)x - \\sigma^{-1}(\\mu_i^T \\mu_i - \\mu_j^T \\mu_j) = 0\n",
    "$$\n",
    "入力ベクトルと、2つのクラスの平均ベクトルとの間のユークリッド距離（の二乗）が小さな方のクラスに分類される。これが最近傍法と呼ばれるアルゴリズムである。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
